# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W9ym5_ewTwRH_7exPAkODIIptmW-lfuY
"""

import numpy as np
import matplotlib.pyplot as plt

# Objective function
def objective_function(position):
    x, y = position
    return x**2 + y**2

# PSO Parameters
num_particles = 30
num_iterations = 100
w = 0.5       # inertia weight
c1 = 1.5      # cognitive coefficient
c2 = 1.5      # social coefficient

bounds = (-10, 10)

# Initialize particles
positions = np.random.uniform(bounds[0], bounds[1], (num_particles, 2))
velocities = np.random.uniform(-1, 1, (num_particles, 2))

# Personal best
pbest_positions = positions.copy()
pbest_values = np.array([objective_function(p) for p in positions])

# Global best
gbest_index = np.argmin(pbest_values)
gbest_position = pbest_positions[gbest_index].copy()
gbest_value = pbest_values[gbest_index]

# History for convergence plot
history = []

# PSO loop
for t in range(num_iterations):
    for i in range(num_particles):
        r1 = np.random.rand()
        r2 = np.random.rand()

        # Update velocity
        velocities[i] = (
            w * velocities[i]
            + c1 * r1 * (pbest_positions[i] - positions[i])
            + c2 * r2 * (gbest_position - positions[i])
        )

        # Update position
        positions[i] += velocities[i]

        # Apply bounds
        positions[i] = np.clip(positions[i], bounds[0], bounds[1])

        # Evaluate fitness
        fitness = objective_function(positions[i])

        # Update personal best
        if fitness < pbest_values[i]:
            pbest_positions[i] = positions[i].copy()
            pbest_values[i] = fitness

    # Update global best (after all particles)
    best_index = np.argmin(pbest_values)
    if pbest_values[best_index] < gbest_value:
        gbest_value = pbest_values[best_index]
        gbest_position = pbest_positions[best_index].copy()

    history.append(gbest_value)

print(f"Global best position: {gbest_position}")
print(f"Global best value: {gbest_value}")

# Plot convergence
plt.plot(history)
plt.xlabel("Iteration")
plt.ylabel("Best Fitness Value")
plt.title("PSO Convergence on f(x, y) = x² + y²")
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Objective function
def f(x):
    return x[0]**2 + x[1]**2

# Parameters
n_particles = 20
iterations = 50
w, c1, c2 = 0.5, 1.5, 1.5

# Initialize
X = np.random.uniform(-10, 10, (n_particles, 2))
V = np.random.uniform(-1, 1, (n_particles, 2))

pbest = X.copy()
pbest_val = np.array([f(x) for x in X])

gbest = pbest[np.argmin(pbest_val)]
gbest_val = np.min(pbest_val)

history = []

# PSO loop
for _ in range(iterations):
    for i in range(n_particles):
        r1, r2 = np.random.rand(), np.random.rand()

        # Update velocity and position
        V[i] = w*V[i] + c1*r1*(pbest[i] - X[i]) + c2*r2*(gbest - X[i])
        X[i] += V[i]

        # Evaluate
        val = f(X[i])

        # Update personal best
        if val < pbest_val[i]:
            pbest[i] = X[i].copy()
            pbest_val[i] = val

    # Update global best
    gbest = pbest[np.argmin(pbest_val)]
    gbest_val = np.min(pbest_val)

    history.append(gbest_val)

print("Best position:", gbest)
print("Best value:", gbest_val)

# Plot convergence
plt.plot(history)
plt.xlabel("Iteration")
plt.ylabel("Best Value")
plt.title("PSO Convergence")
plt.grid()
plt.show()